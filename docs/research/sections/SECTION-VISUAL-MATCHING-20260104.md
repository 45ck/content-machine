# Section Research: Visual Matching & Footage

**Research Date:** 2026-01-04  
**Section:** System Design Section 6.3 - `cm visuals` Command  
**Status:** Complete

---

## 1. Research Questions

This document investigates footage matching and retrieval patterns across vendored repositories to inform content-machine's `cm visuals` command design.

**Key Questions:**
1. Which stock footage APIs are used?
2. How are search queries constructed from script content?
3. Keyword-based vs semantic/embedding-based search?
4. How is video duration matched to scene duration?
5. What fallback strategies exist when no match is found?

---

## 2. Vendor Evidence Summary

### Stock Footage APIs

| Repo | Pexels | Pixabay | Unsplash |
|------|--------|---------|----------|
| short-video-maker-gyori | ✅ Primary | ❌ | ❌ |
| MoneyPrinterTurbo | ✅ Primary | ✅ Secondary | ❌ |
| ShortGPT | ✅ Primary | ❌ | ❌ |

### Matching Approach

**All repos use keyword-based search.** No semantic/embedding-based matching was found in any vendor. Search terms are:
1. Generated by LLM from script content
2. Passed directly to Pexels/Pixabay APIs
3. Multiple fallback terms attempted sequentially

---

## 3. Evidence: short-video-maker-gyori (Pexels TypeScript)

**Source:** [vendor/short-video-maker-gyori/src/short-creator/libraries/Pexels.ts](../../../vendor/short-video-maker-gyori/src/short-creator/libraries/Pexels.ts)

### 3.1 Pexels API Integration

```typescript
const jokerTerms: string[] = ["nature", "globe", "space", "ocean"];
const durationBufferSeconds = 3;
const defaultTimeoutMs = 5000;
const retryTimes = 3;

export class PexelsAPI {
  constructor(private API_KEY: string) {}

  private async _findVideo(
    searchTerm: string,
    minDurationSeconds: number,
    excludeIds: string[],
    orientation: OrientationEnum,
    timeout: number,
  ): Promise<Video> {
    const headers = new Headers();
    headers.append("Authorization", this.API_KEY);
    
    const response = await fetch(
      `https://api.pexels.com/videos/search?` +
      `orientation=${orientation}&size=medium&per_page=80&` +
      `query=${encodeURIComponent(searchTerm)}`,
      {
        method: "GET",
        headers,
        redirect: "follow",
        signal: AbortSignal.timeout(timeout),
      },
    );
    // ...
  }
}
```

**Pattern:**
- Pexels API v1 with Authorization header
- `orientation` parameter for portrait/landscape
- `per_page=80` for broad selection
- Timeout with AbortSignal

### 3.2 Duration and Resolution Filtering

```typescript
const { width: requiredVideoWidth, height: requiredVideoHeight } =
  getOrientationConfig(orientation);

const filteredVideos = videos
  .map((video) => {
    if (excludeIds.includes(video.id)) return;  // Exclude already used
    if (!video.video_files.length) return;

    // FPS normalization (handle slow-motion videos)
    const fps = video.video_files[0].fps;
    const duration = fps < 25 ? video.duration * (fps / 25) : video.duration;

    // Duration check with buffer
    if (duration >= minDurationSeconds + durationBufferSeconds) {
      for (const file of video.video_files) {
        if (
          file.quality === "hd" &&
          file.width === requiredVideoWidth &&
          file.height === requiredVideoHeight
        ) {
          return {
            id: video.id,
            url: file.link,
            width: file.width,
            height: file.height,
          };
        }
      }
    }
  })
  .filter(Boolean);
```

**Pattern:**
- **Exact resolution match**: 1080×1920 (portrait) or 1920×1080 (landscape)
- **FPS normalization**: Slow-motion videos (fps < 25) have effective duration adjusted
- **Duration buffer**: 3 seconds extra to ensure full scene coverage
- **HD quality filter**: Only select HD files
- **Exclude list**: Avoid reusing same video in same video project

### 3.3 Fallback Strategy with Joker Terms

```typescript
async findVideo(
  searchTerms: string[],
  minDurationSeconds: number,
  excludeIds: string[] = [],
  orientation: OrientationEnum = OrientationEnum.portrait,
): Promise<Video> {
  const shuffledJokerTerms = jokerTerms.sort(() => Math.random() - 0.5);
  const shuffledSearchTerms = searchTerms.sort(() => Math.random() - 0.5);

  // Try user terms first, then fallback to joker terms
  for (const searchTerm of [...shuffledSearchTerms, ...shuffledJokerTerms]) {
    try {
      return await this._findVideo(
        searchTerm,
        minDurationSeconds,
        excludeIds,
        orientation,
        timeout,
      );
    } catch (error: unknown) {
      logger.error(error, "Error finding video for term");
    }
  }
  
  throw new Error("No videos found in Pexels API");
}
```

**Pattern:**
- **Shuffle order**: Random term order for variety
- **User terms first**: Try provided search terms
- **Joker fallback**: `["nature", "globe", "space", "ocean"]` as generic fallbacks
- **Fail only after all attempts**: Only throw if all terms fail

---

## 4. Evidence: MoneyPrinterTurbo (Pexels + Pixabay Python)

**Source:** [vendor/MoneyPrinterTurbo/app/services/material.py](../../../vendor/MoneyPrinterTurbo/app/services/material.py)

### 4.1 Pexels API (Python)

```python
def search_videos_pexels(
    search_term: str,
    minimum_duration: int,
    video_aspect: VideoAspect = VideoAspect.portrait,
) -> List[MaterialInfo]:
    aspect = VideoAspect(video_aspect)
    video_orientation = aspect.name
    video_width, video_height = aspect.to_resolution()
    
    api_key = get_api_key("pexels_api_keys")
    headers = {
        "Authorization": api_key,
        "User-Agent": "Mozilla/5.0 ...",
    }
    
    params = {
        "query": search_term, 
        "per_page": 20, 
        "orientation": video_orientation
    }
    query_url = f"https://api.pexels.com/videos/search?{urlencode(params)}"
    
    r = requests.get(query_url, headers=headers, proxies=config.proxy)
    response = r.json()
    
    video_items = []
    for v in response["videos"]:
        duration = v["duration"]
        if duration < minimum_duration:
            continue
            
        for video in v["video_files"]:
            w = int(video["width"])
            h = int(video["height"])
            if w == video_width and h == video_height:
                item = MaterialInfo()
                item.provider = "pexels"
                item.url = video["link"]
                item.duration = duration
                video_items.append(item)
                break
    
    return video_items
```

**Pattern:**
- Same resolution matching as TypeScript version
- Returns list of all matching videos (not just one)
- Duration filter at API response level
- Proxy support for restricted networks

### 4.2 Pixabay API (Alternative Source)

```python
def search_videos_pixabay(
    search_term: str,
    minimum_duration: int,
    video_aspect: VideoAspect = VideoAspect.portrait,
) -> List[MaterialInfo]:
    api_key = get_api_key("pixabay_api_keys")
    
    params = {
        "q": search_term,
        "video_type": "all",
        "per_page": 50,
        "key": api_key,
    }
    query_url = f"https://pixabay.com/api/videos/?{urlencode(params)}"
    
    # Similar filtering logic...
```

**Pattern:**
- Different API parameter names (`q` vs `query`)
- API key in query string (not header)
- `video_type: all` for broad results
- Same duration/resolution filtering

### 4.3 API Key Rotation

```python
requested_count = 0

def get_api_key(cfg_key: str):
    api_keys = config.app.get(cfg_key)
    
    if isinstance(api_keys, str):
        return api_keys
    
    global requested_count
    requested_count += 1
    return api_keys[requested_count % len(api_keys)]
```

**Pattern:** Round-robin rotation through multiple API keys for rate limit distribution.

---

## 5. Evidence: Search Term Generation

### 5.1 From ShortGPT YAML Prompt

**Source:** [vendor/ShortGPT/shortGPT/prompt_templates/editing_generate_videos.yaml](../../../vendor/ShortGPT/shortGPT/prompt_templates/editing_generate_videos.yaml)

```yaml
chat_prompt: |
  For each time segment (4-5 seconds long), you need to suggest 3 alternative 
  search queries that could be used to find appropriate video footage. 
  Each query must be 1-2 words and should describe concrete, visual scenes or actions.

  Guidelines for queries:
  1. Use ONLY English words
  2. Keep queries between 1-2 words
  3. Focus on visual, concrete objects or actions
  4. Avoid abstract concepts
  5. Include both static and dynamic scenes
  6. Ensure queries are family-friendly and safe for monetization

  Good examples:
  - "ocean waves"
  - "typing keyboard"
  - "city traffic"

  Bad examples:
  - "feeling sad" (abstract)
  - "beautiful nature landscape morning sun" (too many words)
  - "confused thoughts" (not visual)
```

**Pattern:** LLM guidance for visual, concrete, 1-2 word search terms.

### 5.2 From MoneyPrinterTurbo Prompt

**Source:** [vendor/MoneyPrinterTurbo/app/services/llm.py](../../../vendor/MoneyPrinterTurbo/app/services/llm.py)

```python
prompt = f"""
# Role: Video Search Terms Generator

## Goals:
Generate {amount} search terms for stock videos, depending on the subject of a video.

## Constrains:
1. the search terms are to be returned as a json-array of strings.
2. each search term should consist of 1-3 words, always add the main subject of the video.
3. you must only return the json-array of strings.
4. the search terms must be related to the subject of the video.
5. reply with english search terms only.

## Output Example:
["search term 1", "search term 2", "search term 3"]
"""
```

**Pattern:** 1-3 words, JSON array output, English only.

---

## 6. Key Findings

### 6.1 No Semantic Search in Vendors

All vendored repos use **keyword-based search only**. Search flow:

```
Script → LLM generates keywords → Direct Pexels API query → Filter results
```

**Opportunity for content-machine:** Implement embedding-based semantic matching:
```
Script → Generate embedding → Search embedding index → Rank by similarity
```

### 6.2 Resolution Requirements

| Aspect | Width | Height | Use Case |
|--------|-------|--------|----------|
| Portrait (9:16) | 1080 | 1920 | TikTok, Reels, Shorts |
| Landscape (16:9) | 1920 | 1080 | YouTube, Twitter |
| Square (1:1) | 1080 | 1080 | Instagram Feed |

### 6.3 Duration Matching

```
Required scene duration + buffer (3s) ≤ Video duration
```

Buffer accounts for:
- Transition effects
- Cutting margin
- Scene timing adjustments

---

## 7. Synthesis: Recommended Patterns for content-machine

### 7.1 Footage Provider Abstraction

```typescript
// src/visuals/providers/types.ts
export interface FootageProvider {
  name: string;
  search(query: FootageQuery): Promise<FootageResult[]>;
  download(url: string, outputPath: string): Promise<void>;
}

export interface FootageQuery {
  searchTerms: string[];
  minDurationSec: number;
  orientation: 'portrait' | 'landscape' | 'square';
  excludeIds?: string[];
}

export interface FootageResult {
  id: string;
  provider: string;
  url: string;
  durationSec: number;
  width: number;
  height: number;
  previewUrl?: string;
}
```

### 7.2 Pexels Provider Implementation

```typescript
// src/visuals/providers/pexels.ts
export class PexelsProvider implements FootageProvider {
  name = 'pexels';
  
  constructor(private apiKey: string) {}
  
  async search(query: FootageQuery): Promise<FootageResult[]> {
    const { width, height } = getResolution(query.orientation);
    
    for (const term of query.searchTerms) {
      const results = await this.searchSingleTerm(term, query);
      if (results.length > 0) {
        return results.filter(r => 
          r.width === width && 
          r.height === height &&
          r.durationSec >= query.minDurationSec + 3
        );
      }
    }
    
    // Fallback to joker terms
    for (const joker of JOKER_TERMS) {
      const results = await this.searchSingleTerm(joker, query);
      if (results.length > 0) return results;
    }
    
    return [];
  }
}
```

### 7.3 Future: Semantic Matching (Embeddings)

```typescript
// src/visuals/semantic.ts (future implementation)
export async function semanticMatch(
  sceneDescription: string,
  footageIndex: FootageIndex
): Promise<FootageResult[]> {
  // 1. Generate embedding for scene description
  const embedding = await generateEmbedding(sceneDescription);
  
  // 2. Query vector database for similar footage
  const matches = await footageIndex.query(embedding, { topK: 10 });
  
  // 3. Re-rank by relevance score
  return matches.sort((a, b) => b.score - a.score);
}
```

### 7.4 Output Schema

```typescript
// src/visuals/schema.ts
import { z } from 'zod';

export const FootageMatchSchema = z.object({
  sceneIndex: z.number().nonnegative(),
  provider: z.enum(['pexels', 'pixabay', 'local']),
  videoId: z.string(),
  videoUrl: z.string().url(),
  localPath: z.string().optional(),
  durationSec: z.number().positive(),
  width: z.number().positive(),
  height: z.number().positive(),
  startOffset: z.number().nonnegative().optional(),
});

export const VisualsOutputSchema = z.object({
  footage: z.array(FootageMatchSchema),
  totalDurationSec: z.number().positive(),
  orientation: z.enum(['portrait', 'landscape', 'square']),
});
```

### 7.5 Video Caching Strategy

```typescript
// src/visuals/cache.ts
import { createHash } from 'crypto';
import { existsSync } from 'fs';

export function getCachePath(url: string): string {
  const hash = createHash('md5').update(url).digest('hex');
  return path.join(CACHE_DIR, `${hash}.mp4`);
}

export async function downloadOrCache(
  url: string,
  outputPath: string
): Promise<string> {
  const cachePath = getCachePath(url);
  
  if (existsSync(cachePath)) {
    // Copy from cache
    await copyFile(cachePath, outputPath);
    return outputPath;
  }
  
  // Download and cache
  await downloadFile(url, cachePath);
  await copyFile(cachePath, outputPath);
  return outputPath;
}
```

---

## 8. Key Takeaways

| Pattern | Source | Adoption Priority |
|---------|--------|-------------------|
| Pexels API integration | short-video-maker-gyori, MoneyPrinterTurbo | **Must have** |
| Exact resolution matching | All repos | **Must have** |
| Duration buffer (+3s) | short-video-maker-gyori | **Must have** |
| Joker fallback terms | short-video-maker-gyori | **Should have** |
| API key rotation | MoneyPrinterTurbo | **Should have** |
| Exclude used video IDs | short-video-maker-gyori | **Should have** |
| MD5-based caching | MoneyPrinterTurbo | Nice to have |
| Semantic/embedding search | None (opportunity) | Future |

---

## 9. References to Existing Research

- [00-SUMMARY-20260102.md](../00-SUMMARY-20260102.md) - Architecture overview
- [01-moneyprinter-turbo-20260102.md](../01-moneyprinter-turbo-20260102.md) - Pexels + Pixabay
- [10-short-video-maker-gyori-20260102.md](../10-short-video-maker-gyori-20260102.md) - Pexels TypeScript
- [SECTION-SCRIPT-GENERATION-20260104.md](SECTION-SCRIPT-GENERATION-20260104.md) - Search term generation

---

## 10. Next Steps

1. Create `FootageProvider` interface
2. Implement `PexelsProvider` with TypeScript
3. Add Pixabay provider as secondary source
4. Define `VisualsOutputSchema` with Zod
5. Implement video caching layer
6. Add search term retry logic with fallbacks
7. (Future) Prototype embedding-based semantic matching
